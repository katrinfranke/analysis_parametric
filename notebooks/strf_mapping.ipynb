{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from in_silico.model.mlflow_loader import ModelPaths, DataPaths, load_free_viewing_model_from_mlflow\n",
    "\n",
    "model_paths = ModelPaths(\n",
    "    checkpoint_uri=\"mlflow-artifacts:/621818231566971674/2f85fd6f5dda46e280456d3186618e1c/artifacts/6806be20120f307fa684cd4c637ad949_final.pth.tar\",\n",
    "    config_uri=\"mlflow-artifacts:/621818231566971674/2f85fd6f5dda46e280456d3186618e1c/artifacts/config.yaml\",\n",
    ")\n",
    "\n",
    "data_paths = DataPaths(\n",
    "    base_dir=\"/gpfs01/euler/data/Data/\",\n",
    ")\n",
    "\n",
    "out = load_free_viewing_model_from_mlflow(model_paths=model_paths, data_paths=data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from in_silico.model.wrapper import ModelWrapper\n",
    "\n",
    "model, skip_samples, cfg, extra = out\n",
    "\n",
    "if skip_samples is None:\n",
    "    skip_samples = cfg.trainer.skip_n_samples\n",
    "\n",
    "wrapper = ModelWrapper(model=model, skip_samples=skip_samples)\n",
    "print(f\"skip_samples = {skip_samples}\")\n",
    "# With num_frames=12 and skip_samples=3, T_pred = 12 - 3 = 9 predicted frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_v3a = np.load('/workdir/analysis_parametric/indices_v3a.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create noise stimulus and preview\n",
    "\n",
    "Each frame in the 12-frame batch is an independent random noise pattern. The noise is\n",
    "block-based: every `block_size_px × block_size_px` region of the image shares one\n",
    "random value. Three independent RGB channels are generated.\n",
    "\n",
    "**Key parameters:**\n",
    "- `block_size_px` – effective spatial resolution of the noise (larger → coarser)\n",
    "- `noise_type` – `\"white\"` for i.i.d. binary (±1) blocks, `\"pink\"` for 1/f spatial correlations\n",
    "- `num_frames` – must match the model's expected batch length (12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from in_silico.stimuli.white_noise import WhiteNoiseSpec, make_white_noise\n",
    "\n",
    "spec = WhiteNoiseSpec(\n",
    "    num_frames=12,\n",
    "    fps=30.0,\n",
    "    block_size_px=10,   # 10×10 px per noise unit\n",
    "    noise_type=\"white\", # \"white\" or \"pink\"\n",
    "    contrast=1.0,\n",
    "    mean_lum=0.5,\n",
    "    seed=0,\n",
    "    rgb=True,           # 3 independent colour channels\n",
    ")\n",
    "\n",
    "frames_example = make_white_noise(spec)  # (T=12, C=3, H=236, W=420)\n",
    "print(f\"frames shape: {frames_example.shape}  dtype: {frames_example.dtype}\")\n",
    "print(f\"value range: [{frames_example.min():.3f}, {frames_example.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview: show 6 consecutive frames to confirm each frame is independent\n",
    "fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "for t, ax in enumerate(axes.flat):\n",
    "    ax.imshow(frames_example[t].transpose(1, 2, 0))  # (H, W, 3)\n",
    "    ax.set_title(f\"frame {t}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"White noise stimulus – one independent pattern per frame\", y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step: predict responses and compute stRF\n",
    "\n",
    "The spatiotemporal RF (stRF) is estimated by **reverse correlation**:\n",
    "\n",
    "$$\n",
    "\\text{stRF}[u, \\tau, c, h, w] \\;=\\;\n",
    "\\frac{\\sum_{n,t}\\; r[n, u, t]\\; s[n, t-\\tau, c, h, w]}{\\sum_{n,t}\\; 1}\n",
    "$$\n",
    "\n",
    "where $r[n,u,t]$ is the predicted response of neuron $u$ at time $t$ for stimulus $n$,\n",
    "and $s[n,t-\\tau,c,h,w]$ is the stimulus frame $\\tau$ steps before that response.\n",
    "\n",
    "**Lag convention:** lag 0 = simultaneous stimulus–response; lag $k$ = stimulus\n",
    "$k$ frames before the response. Larger lags reveal longer neural latencies.\n",
    "\n",
    "**Frame budget with this model:**\n",
    "- 12 input frames → 9 predicted frames (skip_samples = 3)\n",
    "- With `n_lags=4` (lags 0–3) all 9 predicted frames contribute equally to every lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from in_silico.analyses.strf_mapping import predict_responses_strf\n",
    "\n",
    "N = 1000          # number of stimuli (increase for better SNR, e.g. 5000–10000)\n",
    "batch_size = 10   # stimuli per forward pass\n",
    "ds_factor = 4     # spatial downsampling of stored frames (4× → 59×105 px)\n",
    "\n",
    "frames_all, pred_all, seeds = predict_responses_strf(\n",
    "    wrapper,\n",
    "    key=\"37_3843837605846_0_V3A_V4\",\n",
    "    spec=spec,\n",
    "    N=N,\n",
    "    batch_size=batch_size,\n",
    "    ds_factor=ds_factor,\n",
    ")\n",
    "\n",
    "print(f\"frames_all : {frames_all.shape}   (N, T, C, H_ds, W_ds)\")\n",
    "print(f\"pred_all   : {pred_all.shape}     (N, U, T_pred)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from in_silico.analyses.strf_mapping import compute_spatiotemporal_sta\n",
    "\n",
    "# skip_frames = num_frames - T_pred = 12 - 9 = 3\n",
    "skip_frames = frames_all.shape[1] - pred_all.shape[2]\n",
    "print(f\"skip_frames = {skip_frames}\")\n",
    "\n",
    "strf = compute_spatiotemporal_sta(\n",
    "    frames_all,\n",
    "    pred_all,\n",
    "    skip_frames=skip_frames,\n",
    "    n_lags=4,          # lags 0, 1, 2, 3\n",
    "    center_stim=True,\n",
    "    center_resp=True,\n",
    "    baseline=0.5,\n",
    ")\n",
    "\n",
    "print(f\"strf shape : {strf.shape}   (U, n_lags, C, H_ds, W_ds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise stRF – one neuron, all lags\n",
    "\n",
    "For each lag the spatial map shows which pixels drove the neuron:\n",
    "- **Warm colours** (above grey) → ON response: the neuron preferred bright stimulation at that location.\n",
    "- **Cool colours** (below grey) → OFF response.\n",
    "\n",
    "The lag at which the map is sharpest indicates the neuron's preferred latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from in_silico.analyses.strf_mapping import strf_to_rgb\n",
    "\n",
    "# Select a neuron to inspect (change this index to browse different neurons)\n",
    "neuron_idx = 0\n",
    "\n",
    "strf_u = strf[neuron_idx]        # (n_lags, C, H_ds, W_ds)\n",
    "lag_images = strf_to_rgb(\n",
    "    strf_u,\n",
    "    mode=\"robust\",\n",
    "    p=99.5,\n",
    "    shared_scale=True,  # compare amplitudes across lags\n",
    ")\n",
    "\n",
    "fps = spec.fps\n",
    "fig, axes = plt.subplots(1, len(lag_images), figsize=(4 * len(lag_images), 4))\n",
    "if len(lag_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for j, (img, ax) in enumerate(zip(lag_images, axes)):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"lag {j}  ({j / fps * 1000:.0f} ms)\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"stRF – neuron {neuron_idx}\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise stRF – multiple neurons\n",
    "\n",
    "Each row is one neuron; each column is one lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons_show = 6\n",
    "n_lags_show = strf.shape[1]\n",
    "\n",
    "# Pick neurons with the highest stRF power (summed across all lags and pixels)\n",
    "strf_power = (strf ** 2).sum(axis=(1, 2, 3, 4))   # (U,)\n",
    "top_neurons = np.argsort(strf_power)[::-1][:n_neurons_show]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_neurons_show, n_lags_show,\n",
    "    figsize=(3.5 * n_lags_show, 3 * n_neurons_show),\n",
    ")\n",
    "\n",
    "for row, u in enumerate(top_neurons):\n",
    "    lag_images = strf_to_rgb(strf[u], mode=\"robust\", p=99.5, shared_scale=True)\n",
    "    for col, img in enumerate(lag_images):\n",
    "        ax = axes[row, col]\n",
    "        ax.imshow(img)\n",
    "        if row == 0:\n",
    "            ax.set_title(f\"lag {col}  ({col / spec.fps * 1000:.0f} ms)\", fontsize=11)\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(f\"neuron {u}\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"stRF – top neurons by RF power\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full pipeline (single call)\n",
    "\n",
    "Once you are happy with the parameters, use `compute_strf` to run the\n",
    "complete pipeline and optionally save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from in_silico.analyses.strf_mapping import compute_strf\n",
    "\n",
    "strf_full = compute_strf(\n",
    "    wrapper,\n",
    "    key=\"37_3843837605846_0_V3A_V4\",\n",
    "    # --- stimulus ---\n",
    "    num_frames=12,\n",
    "    fps=30.0,\n",
    "    block_size_px=10,\n",
    "    noise_type=\"white\",\n",
    "    contrast=1.0,\n",
    "    mean_lum=0.5,\n",
    "    base_seed=0,\n",
    "    rgb=True,\n",
    "    N=1000,\n",
    "    batch_size=10,\n",
    "    ds_factor=4,\n",
    "    # --- stRF ---\n",
    "    skip_frames=3,     # = num_frames - T_pred\n",
    "    n_lags=4,\n",
    "    output_path=\"../results/strf_v3a.npy\",  # set to None to skip saving\n",
    ")\n",
    "\n",
    "print(f\"strf_full shape: {strf_full.shape}   (U, n_lags, C, H_ds, W_ds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare white noise vs. pink noise\n",
    "\n",
    "Pink noise has 1/f spatial correlations (more energy at low spatial frequencies),\n",
    "which can improve SNR for neurons with large, smooth receptive fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_pink = WhiteNoiseSpec(\n",
    "    num_frames=12,\n",
    "    fps=30.0,\n",
    "    block_size_px=10,\n",
    "    noise_type=\"pink\",\n",
    "    contrast=1.0,\n",
    "    mean_lum=0.5,\n",
    "    seed=0,\n",
    "    rgb=True,\n",
    ")\n",
    "\n",
    "frames_pink = make_white_noise(spec_pink)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].imshow(frames_example[0].transpose(1, 2, 0))\n",
    "axes[0].set_title(\"white noise (frame 0)\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(frames_pink[0].transpose(1, 2, 0))\n",
    "axes[1].set_title(\"pink noise (frame 0)\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
